ITERATIVE RANDOM FOREST
=======================================
NUMBER OF TREES: 20
MAX BINS: 16
MAX DEPTH: 5

STOPPING CONDITION: FMEASURE < 0.97 OR #ITER>1000

EXECUTION ENVIRONMENT (Cineca Pico https://www.cineca.it/it/content/pico)
HADOOP: 2.5.1
JAVA: Oracle jdk1.8.0_131
SPARK: 2.1.1 over YARN Cluster
	3 nodes
	each node:
		20 CPUs
		96 GB RAM

#############################################################
## Environment configuration
module load profile/advanced hadoop/2.5.1
export JAVA_HOME=$HOME/java/jdk1.8.0_131
export SPARK_HOME=$HOME/spark/spark-2.1.1-bin-hadoop2.4
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar

# prepare hdfs
$HADOOP_HOME/bin/hdfs dfs -mkdir /user
$HADOOP_HOME/bin/hdfs dfs -mkdir /user/me
$HADOOP_HOME/bin/hdfs dfs -mkdir /user/me/input

# copy input file
$HADOOP_HOME/bin/hdfs dfs -put $HOME/camur/brca.csv /user/me/input

# Spark Job
$HOME/spark/spark-2.1.1-bin-hadoop2.4/bin/spark-submit --class "it.cnr.camur.experiments.Classifier_Iterat_RandomForest" --master yarn --deploy-mode cluster --driver-memory 30g --executor-memory 30g --executor-cores 10 --queue default $HOME/camur/camur-1.0.0.jar 1000 0.97 5 16 20 /user/me/input/brca.csv $HOME/camur/EXPERIMENTS $HOME/camur/BRCA_mapping.csv $HOME/camur/cpg2genes.csv

#close hdfs
$HADOOP_HOME/bin/hdfs dfs -rm -r /user/me/input
